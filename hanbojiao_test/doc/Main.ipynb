{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and split them into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=os.path.dirname(os.path.dirname(os.path.realpath(\"main.ipynb\")))  \n",
    "# ...\\\\Spring2020-Project3-group2\n",
    "os.chdir(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above output is not correct. Please enter the filepath below to '..../Spring2020-Project3-group2/' manually. Thank you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/jiaoh/Documents/GitHub/Spring2020-Project3-group2/hanbojiao_test/'\n",
    "#####################   Modify above path   #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(filepath)\n",
    "\n",
    "# testpath=filepath+'/data/test_set/'\n",
    "trainpath=filepath+'/data/train_set/'\n",
    "\n",
    "# test_image_dir = testpath + \"images/\"\n",
    "# test_pt_dir = testpath + \"points/\"\n",
    "train_image_dir = trainpath + \"images/\"\n",
    "train_pt_dir = trainpath + \"points/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics.pairwise\n",
    "def pairwise_dist(vec):\n",
    "    dist  = sklearn.metrics.pairwise_distances(vec, metric='euclidean')\n",
    "    np.fill_diagonal(dist, np.nan)\n",
    "    return dist\n",
    "def feature(fiducial_pt_list,index):\n",
    "    pairwise_dist_feature = pairwise_dist(fiducial_pt_list[index]).flatten()\n",
    "    pairwise_dist_feature = pairwise_dist_feature[~np.isnan(pairwise_dist_feature)]\n",
    "    return pairwise_dist_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = time.time()\n",
    "dataDir = train_pt_dir\n",
    "fiducial_pt_list = []\n",
    "filelist = []\n",
    "for file in os.listdir(dataDir):\n",
    "    filelist.append(file)\n",
    "filelist.sort()\n",
    "for file in filelist:\n",
    "    fiducial_pt_list.append(scipy.io.loadmat(dataDir+file))\n",
    "    l = []\n",
    "for i in range(len(fiducial_pt_list)):\n",
    "    if 'faceCoordinatesUnwarped' in fiducial_pt_list[i].keys():\n",
    "        l.append(fiducial_pt_list[i]['faceCoordinatesUnwarped'])\n",
    "    else:\n",
    "        l.append(fiducial_pt_list[i]['faceCoordinates2'])\n",
    "        \n",
    "fiducial_pt_list = l\n",
    "\n",
    "\n",
    "X = pd.DataFrame(np.zeros((2500, 6006)))\n",
    "for i in range(2500):\n",
    "    X.iloc[i,:] = np.round(feature(fiducial_pt_list, i).flatten(), 0)\n",
    "y =pd.read_csv(trainpath+'label.csv')['emotion_idx']\n",
    "f1 = time.time()-f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction time: 2.006s\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Extraction time: %0.3fs\" % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "train_x_dis,test_x_dis,train_y_dis,test_y_dis=train_test_split(X,y,test_size=0.2,random_state=3662)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the summary of all models we tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Claimed Accuracy</th>\n",
       "      <th>Training Time/s</th>\n",
       "      <th>Testing Time/s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Bseline model:GBM</td>\n",
       "      <td>41.92%</td>\n",
       "      <td>435.736s</td>\n",
       "      <td>0.021s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Knn</td>\n",
       "      <td>30.36%</td>\n",
       "      <td>0.414s</td>\n",
       "      <td>9.944s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Improved GBM</td>\n",
       "      <td>43.32%</td>\n",
       "      <td>946.633s</td>\n",
       "      <td>0.030s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>XGboost</td>\n",
       "      <td>47.12%</td>\n",
       "      <td>119.812s</td>\n",
       "      <td>0.189s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>45.48%</td>\n",
       "      <td>6.888s</td>\n",
       "      <td>0.030s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>54.00%</td>\n",
       "      <td>33.373s</td>\n",
       "      <td>0.009s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>SVM</td>\n",
       "      <td>50.04%</td>\n",
       "      <td>17.806s</td>\n",
       "      <td>5.440s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>49.44%</td>\n",
       "      <td>298.493s</td>\n",
       "      <td>0.173s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Final model: VotingClassifier</td>\n",
       "      <td>???</td>\n",
       "      <td>436.136s</td>\n",
       "      <td>6.124s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model Claimed Accuracy Training Time/s  \\\n",
       "0              Bseline model:GBM           41.92%        435.736s   \n",
       "1                            Knn           30.36%          0.414s   \n",
       "2                   Improved GBM           43.32%        946.633s   \n",
       "3                        XGboost           47.12%        119.812s   \n",
       "4         RandomForestClassifier           45.48%          6.888s   \n",
       "5             LogisticRegression           54.00%         33.373s   \n",
       "6                            SVM           50.04%         17.806s   \n",
       "7                  MLPClassifier           49.44%        298.493s   \n",
       "8  Final model: VotingClassifier              ???        436.136s   \n",
       "\n",
       "  Testing Time/s  \n",
       "0         0.021s  \n",
       "1         9.944s  \n",
       "2         0.030s  \n",
       "3         0.189s  \n",
       "4         0.030s  \n",
       "5         0.009s  \n",
       "6         5.440s  \n",
       "7         0.173s  \n",
       "8         6.124s  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Model':['Bseline model:GBM','Knn', 'Improved GBM', 'XGboost','RandomForestClassifier','LogisticRegression', 'SVM','MLPClassifier','Final model: VotingClassifier'], \n",
    "        'Claimed Accuracy':['41.92%', '30.36%', '43.32%','47.12%',  '45.48%', '54.00%', '50.04%','49.44%','???'],\n",
    "        'Training Time/s':['435.736s', '0.414s', '946.633s','119.812s',  '6.888s', '33.373s', '17.806s','298.493s','436.136s'],\n",
    "       'Testing Time/s':['0.021s', '9.944s', '0.030s','0.189s',  '0.030s', '0.009s', '5.440s','0.173s','6.124s'],} \n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model GBM (41.92%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model we used is Boosted Decision Stumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_baseline= GradientBoostingClassifier(n_estimators=100  , max_depth= 1,learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 435.736s; \n",
      "Training Accuracy : 78.1% 0.108s\n",
      "Testing Accuracy : 40.4% 0.021s\n"
     ]
    }
   ],
   "source": [
    "model=gbm_baseline\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.67      0.57        24\n",
      "           2       0.65      0.71      0.68        24\n",
      "           3       0.34      0.36      0.35        28\n",
      "           4       0.23      0.41      0.30        17\n",
      "           5       0.58      0.44      0.50        25\n",
      "           6       0.25      0.20      0.22        20\n",
      "           7       0.50      0.31      0.38        26\n",
      "           8       0.66      0.86      0.75        22\n",
      "           9       0.56      0.47      0.51        19\n",
      "          10       0.50      0.26      0.34        31\n",
      "          11       0.40      0.45      0.43        22\n",
      "          12       0.25      0.29      0.27        21\n",
      "          13       0.31      0.15      0.21        26\n",
      "          14       0.47      0.74      0.57        19\n",
      "          15       0.29      0.45      0.36        11\n",
      "          16       0.60      0.62      0.61        24\n",
      "          17       0.36      0.40      0.38        30\n",
      "          18       0.39      0.30      0.34        23\n",
      "          19       0.21      0.29      0.24        17\n",
      "          20       0.13      0.14      0.13        22\n",
      "          21       0.30      0.35      0.32        23\n",
      "          22       0.33      0.15      0.21        26\n",
      "\n",
      "    accuracy                           0.40       500\n",
      "   macro avg       0.40      0.41      0.39       500\n",
      "weighted avg       0.41      0.40      0.39       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y_dis,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let us find some other advanced model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knn (30.36%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Knn first. But the accuracy is not acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 0.414s; \n",
      "Training Accuracy : 42.4% 39.880s\n",
      "Testing Accuracy : 30.4% 9.944s\n"
     ]
    }
   ],
   "source": [
    "model=knn\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved GBM (43.32%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to improve our baseline model by increasing the \"max_depth\". Its accuracy is improved but the fitting time is longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_improved= GradientBoostingClassifier(n_estimators=100  , max_depth= 2,learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 946.633s; \n",
      "Training Accuracy : 99.1% 0.164s\n",
      "Testing Accuracy : 43.6% 0.030s\n"
     ]
    }
   ],
   "source": [
    "model=gbm_improved\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we try some advanced model, including XGBoost, RandomForestClassifier, LogisticRegression, SVM, MLPclassifier. Their accuracy and fitting time are both improved compared with baseline model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost(47.12%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model_final =xgboost.XGBClassifier(max_depth=4,n_estimators=50,learning_rate=0.1,\n",
    "                       min_child_weight=1,gamma=0,subsample=0.8,colsample_bytree=0.8,reg_alpha=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 119.812s; \n",
      "Training Accuracy : 99.8% 0.728s\n",
      "Testing Accuracy : 46.8% 0.189s\n"
     ]
    }
   ],
   "source": [
    "model=xgboost_model_final\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier (45.48%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_model_final=RandomForestClassifier(n_estimators = 100, criterion = 'gini', \n",
    "                             random_state = 42, min_samples_leaf=1, max_features='sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 6.888s; \n",
      "Training Accuracy : 100.0% 0.116s\n",
      "Testing Accuracy : 42.0% 0.030s\n"
     ]
    }
   ],
   "source": [
    "model=randomforest_model_final\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression (54.00%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_final =LogisticRegression(C=0.01,\n",
    "                                         dual=False,\n",
    "                                         fit_intercept=True,\n",
    "                                         intercept_scaling=1,\n",
    "                                         max_iter=300,\n",
    "                                         multi_class='multinomial',\n",
    "                                         penalty='l2',\n",
    "                                         solver='newton-cg',\n",
    "                                         tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 33.373s; \n",
      "Training Accuracy : 82.7% 0.030s\n",
      "Testing Accuracy : 55.4% 0.009s\n"
     ]
    }
   ],
   "source": [
    "model=logistic_model_final\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (50.04%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_final =SVC(C=0.1,decision_function_shape='ovr',degree=2,gamma=0.1,kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 17.806s; \n",
      "Training Accuracy : 100.0% 21.808s\n",
      "Testing Accuracy : 48.6% 5.440s\n"
     ]
    }
   ],
   "source": [
    "model=svm_model_final\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network-MLPClassifier (49.44%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model_final =MLPClassifier(early_stopping=True,\n",
    "                              hidden_layer_sizes=(3000,),\n",
    "                              learning_rate='adaptive',\n",
    "                              solver='lbfgs',\n",
    "                              validation_fraction=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 298.493s; \n",
      "Training Accuracy : 100.0% 0.576s\n",
      "Testing Accuracy : 48.6% 0.173s\n"
     ]
    }
   ],
   "source": [
    "model=MLP_model_final\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model: VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use VotingClassifier to combine the top models together as the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf_clf',randomforest_model_final),\n",
    "                ('log_clf', logistic_model_final),\n",
    "                ('svm_clf', svm_model_final),\n",
    "               ('xgb_clf', xgboost_model_final),\n",
    "                ('MLP_clf',MLP_model_final)],\n",
    "    voting='hard',\n",
    "#    weights=[0.45,0.54,0.50,0.47,0.49],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 436.136s; \n",
      "Training Accuracy : 100.0% 23.888s\n",
      "Testing Accuracy : 53.0% 6.124s\n"
     ]
    }
   ],
   "source": [
    "model=voting_clf\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.83      0.68        24\n",
      "           2       0.75      0.75      0.75        24\n",
      "           3       0.44      0.50      0.47        28\n",
      "           4       0.34      0.65      0.45        17\n",
      "           5       0.77      0.80      0.78        25\n",
      "           6       0.53      0.50      0.51        20\n",
      "           7       0.50      0.54      0.52        26\n",
      "           8       0.70      0.95      0.81        22\n",
      "           9       0.65      0.58      0.61        19\n",
      "          10       0.65      0.42      0.51        31\n",
      "          11       0.57      0.55      0.56        22\n",
      "          12       0.38      0.38      0.38        21\n",
      "          13       0.33      0.19      0.24        26\n",
      "          14       0.52      0.74      0.61        19\n",
      "          15       0.38      0.55      0.44        11\n",
      "          16       0.73      0.79      0.76        24\n",
      "          17       0.54      0.43      0.48        30\n",
      "          18       0.43      0.39      0.41        23\n",
      "          19       0.20      0.18      0.19        17\n",
      "          20       0.41      0.32      0.36        22\n",
      "          21       0.48      0.43      0.45        23\n",
      "          22       0.54      0.27      0.36        26\n",
      "\n",
      "    accuracy                           0.53       500\n",
      "   macro avg       0.52      0.53      0.52       500\n",
      "weighted avg       0.53      0.53      0.52       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y_dis,model.predict(test_x_dis)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
